{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc42882a-b909-4d88-9f4f-3ef3027ebd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5eed2c39-672d-4acd-9af2-35451a1d1d03",
   "metadata": {},
   "source": [
    "Our goal is to parse a wiki dump from https://cinemorgue.fandom.com/wiki/Special:Statistics to figure out which actor/actress has died the most in movies because I don't believe a single click-bait article I've found online. Trust but verify ya know.\n",
    "\n",
    "Fandom (the site Cinemorgue is hosted on) follows the mediawiki export format of /export-0.11/.\n",
    "Using the xml tree is way easier than relying on any sort of wikiparser library out there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "975b736f-25c5-4f57-bd76-90d9d1399c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cinemorgue Wiki</td>\n",
       "      <td>&lt;mainpage-leftcolumn-start /&gt;\\n{{Mainpage welc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Main Page</td>\n",
       "      <td>#REDIRECT [[Cinemorgue Wiki]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>[[File:Marilynmonroe.jpg|frame|Marilyn Monroe ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title                                               text\n",
       "0  Cinemorgue Wiki  <mainpage-leftcolumn-start />\\n{{Mainpage welc...\n",
       "1        Main Page                      #REDIRECT [[Cinemorgue Wiki]]\n",
       "2   Marilyn Monroe  [[File:Marilynmonroe.jpg|frame|Marilyn Monroe ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NS = 'http://www.mediawiki.org/xml/export-0.11/'\n",
    "\n",
    "def parse_wikimedia_xml(filepath):\n",
    "    tree = ET.parse(filepath)\n",
    "    root = tree.getroot()\n",
    "    data = []\n",
    "    for page in root.findall('{%s}page' % NS):\n",
    "        ns = page.find('{%s}ns' % NS).text\n",
    "        if ns != \"0\":\n",
    "            continue\n",
    "        title = page.find('{%s}title' % NS).text\n",
    "        revision = page.find('{%s}revision' % NS)\n",
    "        text = revision.find('{%s}text' % NS).text\n",
    "        data.append({'title': title, 'text': text})\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "df = parse_wikimedia_xml('input/cinemorgue_8.3.23.xml')\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "31344f7b-8630-4319-87a4-f581f045dc32",
   "metadata": {},
   "source": [
    "We will only be looking at Film Deaths; TV Deaths seem to include a lot of voice actors from animated shows which feels like cheating and ruins the spirt of finding out which actor has died the most. \n",
    "\n",
    "The structure of each wikimedia page, while not perfect, is relatively consistent.\n",
    "\n",
    "Each Actor/Actress page follows the structure below:\n",
    "\n",
    "Overview \n",
    "Film Deaths \n",
    "Television Deaths/TV Deaths \n",
    "Video Game Deaths \n",
    "Music Video Deaths \n",
    "Notable Connections \n",
    "\n",
    "Not every page has the subsequent sections, so just to be thorough, we check for and delete every other section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f02b2c6a-0d6e-4699-b526-6f32443600a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete everything before Film Deaths.\n",
    "df['text'] = df['text'].str.split(\"Film Deaths\", n=1, expand=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3a3284c-3084-460b-80a9-e70786e49682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete everything below TV Deaths.\n",
    "df['text'] = df['text'].str.split(\"Television Deaths\", n=1, expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e887a4fd-1bff-48b1-90fe-002006b1f420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.split(\"TV Deaths\", n=1, expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32f00433-b68e-436d-ab4f-a0cb71f9b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.split(\"TV Series Deaths\", n=1, expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "756966fe-7a62-4b52-94f5-971c20d310b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.split(\"Video Game Deaths\", n=1, expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "286526b2-93ac-4f06-b293-2bfb72a9cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.split(\"Music Video Deaths\", n=1, expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50fb750a-31f5-41e7-a8bb-4fea1f54e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.split(\"Notable Connections\", n=1, expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2287acfa-1f92-4f2e-9117-b6e08f8fcdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.split(\"Noteworthy Connections\", n=1, expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74949947-6ac8-47bc-b058-d447d8f3d69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.split(\"Gallery\", n=1, expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2315a4a-491a-48de-a6c6-9b154c86480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.split(\"Categories\", n=1, expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cb90866-870d-484b-a68e-82881924c46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.split(\"DEFAULTSORT:\", n=1, expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d0c5ab9-2afc-4332-b9a8-e8cab230a1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all recently nulled rows. Ready for splitting.\n",
    "df = df.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a5bce444-c60e-4b6e-b4e5-5de325d8d9f2",
   "metadata": {},
   "source": [
    "Every movie death is (generally) annotated by a line break and an asterisk.\n",
    "For each instance of this, we'll the entry out into a new row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a25aa054-b85a-4e55-adf0-3125761fd2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joseph Cotten</td>\n",
       "      <td>'''[[Shadow of a Doubt (1943)|''Shadow of a Do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joseph Cotten</td>\n",
       "      <td>'''''[[Niagara (1953)]]''''' [''George Loomis'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joseph Cotten</td>\n",
       "      <td>'''''The Last Sunset'' (1961)''' [''John Breck...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title                                               text\n",
       "0  Joseph Cotten  '''[[Shadow of a Doubt (1943)|''Shadow of a Do...\n",
       "1  Joseph Cotten  '''''[[Niagara (1953)]]''''' [''George Loomis'...\n",
       "2  Joseph Cotten  '''''The Last Sunset'' (1961)''' [''John Breck..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New DataFrame to store the split rows\n",
    "new_rows = {'title': [], 'text': []}\n",
    "\n",
    "# Iterate through the original DataFrame\n",
    "for idx, row in df.iterrows():\n",
    "    title = row['title']\n",
    "    text_parts = row['text'].split('\\n*')\n",
    "    \n",
    "    # Append the new rows to the new DataFrame\n",
    "    # Skip the first element, usually contains gibberish before first line.\n",
    "    for part in text_parts[1:]:\n",
    "        new_rows['title'].append(title)\n",
    "        new_rows['text'].append(part)\n",
    "\n",
    "# Create the new DataFrame\n",
    "new_df = pd.DataFrame(new_rows)\n",
    "\n",
    "# Print the result\n",
    "new_df.head(3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e0987a7-8b6c-4860-8ab0-703053961e6e",
   "metadata": {},
   "source": [
    "Now we need to find the year the film was released. \n",
    "This is to help differentiate common/repeated movie titles that have been made over the year.\n",
    "\n",
    "We are looking for the first instance of 4 digits between parentheis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ceae2c2d-c5d4-4508-85dc-cd7274caf9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joseph Cotten</td>\n",
       "      <td>'''[[Shadow of a Doubt (1943)|''Shadow of a Do...</td>\n",
       "      <td>1943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joseph Cotten</td>\n",
       "      <td>'''''[[Niagara (1953)]]''''' [''George Loomis'...</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joseph Cotten</td>\n",
       "      <td>'''''The Last Sunset'' (1961)''' [''John Breck...</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title                                               text  year\n",
       "0  Joseph Cotten  '''[[Shadow of a Doubt (1943)|''Shadow of a Do...  1943\n",
       "1  Joseph Cotten  '''''[[Niagara (1953)]]''''' [''George Loomis'...  1953\n",
       "2  Joseph Cotten  '''''The Last Sunset'' (1961)''' [''John Breck...  1961"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating year column.\n",
    "def extract_year(text):\n",
    "    match = re.search(r'\\((\\d{4})\\)', text)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Apply the function to create the \"year\" column\n",
    "new_df['year'] = new_df['text'].apply(extract_year)\n",
    "\n",
    "new_df.head(3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "612970e8-6de8-4db0-8d5b-c55142030bc3",
   "metadata": {},
   "source": [
    "Now begins the slow stripping away of unncessary info following each movie title.\n",
    "\n",
    "There are a lot of weird cases, and even weirder non alphanumeric characters. \n",
    "So we're going to strip away characters slowly but surely to create uniform pattern we can parse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b6e563c-60b7-42e9-a32b-75ad8ae59270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all pairs of apostraphes or quotation marks.\n",
    "new_df['text'] = new_df['text'].str.replace(r\"[''\\\"\\=]\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51c88ee3-d0ea-4068-8613-2bc4787f4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some titles have stray html formatting tags in them. \n",
    "new_df['text'] = new_df['text'].str.replace(r'\\s*<.*?>\\s*', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "427d1c4f-59ae-4bb3-84c7-93702fcf2ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some titles will just have the link hardcoded in the title which is pretty impressive.\n",
    "new_df['text'] = new_df['text'].str.replace(r'https://\\S+\\s*', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62a9540b-5340-4d59-9d58-e860e0979b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some titles might even hardcode the unsecured link instead.\n",
    "new_df['text'] = new_df['text'].str.replace(r'http://\\S+\\s*', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f5a6426-9df8-43ee-a708-96fc2eee5642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save line contents for additional parsing later.\n",
    "new_df['raw_text'] = new_df['text']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f3c224a-4553-4ee7-ad32-0e3fe3e89ce0",
   "metadata": {},
   "source": [
    "Titles come in two forms: Links and Non-Links.\n",
    "\n",
    "Links are formatted in a way that have the title listed twice between brackets.\n",
    "(e.g. [The Shining (1980) | The Shining (1980)])\n",
    "\n",
    "Non-Links bow to no god, and do whatever they want to do. \n",
    "Our best hope is to just capture everything leading up to the first instance of a year between parenthesis. (e.g. ________ (1980) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2398dea-cd6d-46f3-ab2e-031141319c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a string starts with a link [], grab the contained string.\n",
    "# If a string is not a link, grab all textup until the first date ().\n",
    "def extract_text(row):\n",
    "    if row.startswith(\"[\"):\n",
    "        # Remove parenthesis and their contents from inside the square brackets\n",
    "        cleaned_text = re.sub(r'\\([^()]*\\)', '', row)\n",
    "        match = re.search(r'\\[(.*?)\\]', cleaned_text)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    else:\n",
    "        match = re.search(r'^([^()]*)', row)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "    return ''  # Return an empty string if no match is found\n",
    "\n",
    "new_df['text'] = new_df['text'].apply(extract_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3bed8c5-3c03-458d-88d0-df299bc32207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For links, delete everything after the first instance of a |.\n",
    "new_df['text'] = new_df['text'].str.split(\"|\", n=1, expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0359a349-0040-45f0-a865-e5509ca56f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all remaining [[]].\n",
    "new_df['text'] = new_df['text'].str.replace(r'\\[|\\]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf8677f2-cd19-4647-aa2a-5e32dc24abcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categories sneak their way into some titles, so remove these as well.\n",
    "new_df['text'] = new_df['text'].str.split(\"{\", n=1, expand=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46d71f61-8bd9-46aa-a72b-786f20db2d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all white space at end of string.\n",
    "new_df['text'] = new_df['text'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b796d3e2-5f80-4c97-9c05-88b324226678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all blank rows.\n",
    "new_df = new_df[new_df['year'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "989f3347-9766-4467-81b1-a454d2ec786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all null rows that don't contain a year.\n",
    "new_df = new_df.dropna(subset=['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "335ba050-165a-465f-8b40-23dcf6507df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>raw_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joseph Cotten</td>\n",
       "      <td>Shadow of a Doubt</td>\n",
       "      <td>1943</td>\n",
       "      <td>[[Shadow of a Doubt (1943)|Shadow of a Doubt (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joseph Cotten</td>\n",
       "      <td>Niagara</td>\n",
       "      <td>1953</td>\n",
       "      <td>[[Niagara (1953)]] [George Loomis]: Drowned wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joseph Cotten</td>\n",
       "      <td>The Last Sunset</td>\n",
       "      <td>1961</td>\n",
       "      <td>The Last Sunset (1961) [John Breckenridge]: Sh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title               text  year  \\\n",
       "0  Joseph Cotten  Shadow of a Doubt  1943   \n",
       "1  Joseph Cotten            Niagara  1953   \n",
       "2  Joseph Cotten    The Last Sunset  1961   \n",
       "\n",
       "                                            raw_text  \n",
       "0  [[Shadow of a Doubt (1943)|Shadow of a Doubt (...  \n",
       "1  [[Niagara (1953)]] [George Loomis]: Drowned wh...  \n",
       "2  The Last Sunset (1961) [John Breckenridge]: Sh...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d40d4988-f76b-4539-9617-2c65ea282304",
   "metadata": {},
   "source": [
    "Now we're going to attempt to append cause of death.\n",
    "\n",
    "To define cause of death, we're going to use the FBI's boilerplate for homicide methodology.\n",
    "https://ucr.fbi.gov/crime-in-the-u.s/2019/crime-in-the-u.s.-2019/tables/expanded-homicide-data-table-8.xls\n",
    "\n",
    "I think the least-over-kill method to go about this is tokenizing the text, and hard coding classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a19890d-505d-41bb-a800-a1909f80764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all alphanumeric characters from the column.\n",
    "new_df['raw_text'] = new_df['raw_text'].str.replace(r'[^a-zA-Z#\\s]', ' ', regex=True)\n",
    "\n",
    "# Removes spaces from above. Easier this way.\n",
    "new_df['raw_text'] = new_df['raw_text'].str.replace(r'  +', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee3f3914-a1d0-4d7b-9039-5652cb75cfbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joseph Cotten</td>\n",
       "      <td>Shadow of a Doubt</td>\n",
       "      <td>1943</td>\n",
       "      <td>Shadow of a Doubt Shadow of a Doubt Uncle Cha...</td>\n",
       "      <td>Shadow Doubt Shadow Doubt Uncle Charlie Falls ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joseph Cotten</td>\n",
       "      <td>Niagara</td>\n",
       "      <td>1953</td>\n",
       "      <td>Niagara George Loomis Drowned when his boat s...</td>\n",
       "      <td>Niagara George Loomis Drowned boat sinks going...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joseph Cotten</td>\n",
       "      <td>The Last Sunset</td>\n",
       "      <td>1961</td>\n",
       "      <td>The Last Sunset John Breckenridge Shot in the ...</td>\n",
       "      <td>Last Sunset John Breckenridge Shot back Adam W...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title               text  year  \\\n",
       "0  Joseph Cotten  Shadow of a Doubt  1943   \n",
       "1  Joseph Cotten            Niagara  1953   \n",
       "2  Joseph Cotten    The Last Sunset  1961   \n",
       "\n",
       "                                            raw_text  \\\n",
       "0   Shadow of a Doubt Shadow of a Doubt Uncle Cha...   \n",
       "1   Niagara George Loomis Drowned when his boat s...   \n",
       "2  The Last Sunset John Breckenridge Shot in the ...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  Shadow Doubt Shadow Doubt Uncle Charlie Falls ...  \n",
       "1  Niagara George Loomis Drowned boat sinks going...  \n",
       "2  Last Sunset John Breckenridge Shot back Adam W...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stop words to make stemming less painful.\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = word_tokenize(text)\n",
    "    filtered = [word for word in words if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "new_df['processed_text'] = new_df['raw_text'].apply(remove_stopwords)\n",
    "\n",
    "new_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67a39dc8-222b-43fc-9a4c-564ac2d0b5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joseph Cotten</td>\n",
       "      <td>Shadow of a Doubt</td>\n",
       "      <td>1943</td>\n",
       "      <td>Shadow of a Doubt Shadow of a Doubt Uncle Cha...</td>\n",
       "      <td>shadow doubt shadow doubt uncl charli fall tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joseph Cotten</td>\n",
       "      <td>Niagara</td>\n",
       "      <td>1953</td>\n",
       "      <td>Niagara George Loomis Drowned when his boat s...</td>\n",
       "      <td>niagara georg loomi drown boat sink go niagara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Joseph Cotten</td>\n",
       "      <td>The Last Sunset</td>\n",
       "      <td>1961</td>\n",
       "      <td>The Last Sunset John Breckenridge Shot in the ...</td>\n",
       "      <td>last sunset john breckenridg shot back adam wi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title               text  year  \\\n",
       "0  Joseph Cotten  Shadow of a Doubt  1943   \n",
       "1  Joseph Cotten            Niagara  1953   \n",
       "2  Joseph Cotten    The Last Sunset  1961   \n",
       "\n",
       "                                            raw_text  \\\n",
       "0   Shadow of a Doubt Shadow of a Doubt Uncle Cha...   \n",
       "1   Niagara George Loomis Drowned when his boat s...   \n",
       "2  The Last Sunset John Breckenridge Shot in the ...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  shadow doubt shadow doubt uncl charli fall tra...  \n",
       "1  niagara georg loomi drown boat sink go niagara...  \n",
       "2  last sunset john breckenridg shot back adam wi...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stem everything to get to the root word. It makes what we're doing next way less insane.\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    stemmed = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(stemmed)\n",
    "\n",
    "new_df['processed_text'] = new_df['processed_text'].apply(stem_text)\n",
    "\n",
    "new_df.head(3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "acefb5c2-fd0c-48f0-ac40-5c0f2e41dc8f",
   "metadata": {},
   "source": [
    "# Random sampling text to find most common stems. \n",
    "# This was used to guess and check for the dicitonary below.\n",
    "# The key is to cycle using a small sample size, not a larger list.\n",
    "\n",
    "sample_df = new_df['cleaned_text'].sample(frac=0.0005)\n",
    "# Tokenize and count tokens\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(sample_df)\n",
    "tokens = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Sum across rows to get token counts\n",
    "token_count = np.sum(X.toarray(), axis=0)\n",
    "\n",
    "# Sort tokens by count and get the top (insert number here)\n",
    "sorted_indices = np.argsort(token_count)[-50:]\n",
    "most_common = [(tokens[i], token_count[i]) for i in sorted_indices]\n",
    "\n",
    "print(\"The most common tokens are:\")\n",
    "for item in most_common:\n",
    "    word, count = item\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9bd5d4e8-056e-484c-af6c-b1d40f7f1113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deviated from the  FBI list a little bit.\n",
    "keywords = {\n",
    "    'Firearms': ['gun', 'shot','shoot', 'shootout', 'sniper'],\n",
    "    'Knives/Cutting Instruments': ['knife', 'stab', 'slash', 'decapit', 'slit', 'impal', 'cut', 'sword'],\n",
    "    'Blunt Objects': ['club', 'hammer', 'bludgeon'],\n",
    "    'Personal Weapons': ['fist', 'kick', 'punch'],\n",
    "    'Poison': ['poison', 'cyanid'],\n",
    "    'Explosives': ['explos', 'bomb', 'deton'],\n",
    "    'Fire': ['fire', 'melt', 'burn'],\n",
    "    'Narcotics': ['overdos'],\n",
    "    'Drowning': ['drown', 'sink'],\n",
    "    'Strangulation': ['strangl', 'choke', 'asphyxi', 'hang'],\n",
    "    'Impact': ['fall', 'thrown', 'crash', 'crush'],\n",
    "    'Natural Disaster': ['earthquak', 'tornado'],\n",
    "    'Ailment': ['sick', 'cancer', 'infect', 'heart attack', 'stroke']\n",
    "}\n",
    "\n",
    "# We want to capture the first word that appears in the string that exists in the dictionary.\n",
    "# Start with earliest_index being equal to inf so all valid index will be smaller.\n",
    "# Earliest_index grabs the first index of a word that exists in the dictionary.\n",
    "# Update values whenever a smaller index exists, otherwise skip.\n",
    "\n",
    "def identify_cause(text):\n",
    "    text = word_tokenize(text.lower())\n",
    "    first_instance = None\n",
    "    earliest_index = float('inf')\n",
    "    \n",
    "    for cause, keys in keywords.items():\n",
    "        for key in keys:\n",
    "            if key in text:\n",
    "                index = text.index(key)\n",
    "                if index < earliest_index:\n",
    "                    earliest_index = index\n",
    "                    first_instance = cause\n",
    "                    \n",
    "    if first_instance:\n",
    "        return first_instance\n",
    "    return 'Other'\n",
    "\n",
    "new_df['cause_of_death'] = new_df['processed_text'].apply(identify_cause)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da7c1b9c-401d-4673-908b-cc5e9f22d28d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df.rename(columns={'title': 'Name', 'text': 'Movie', 'year': 'Year'}, inplace=True)\n",
    "new_df.to_csv('output/Cinemorgue.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8bf62e98-986d-461c-8ee2-3e5219c80d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cause_of_death\n",
      "Firearms                      20988\n",
      "Other                         20028\n",
      "Knives/Cutting Instruments    11575\n",
      "Impact                         4835\n",
      "Explosives                     2406\n",
      "Strangulation                  2324\n",
      "Fire                           2264\n",
      "Drowning                       1365\n",
      "Poison                          915\n",
      "Ailment                         763\n",
      "Blunt Objects                   688\n",
      "Personal Weapons                439\n",
      "Narcotics                       356\n",
      "Natural Disaster                 58\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Use the value_counts() method to count occurrences of each unique value\n",
    "count_series = new_df['cause_of_death'].value_counts()\n",
    "\n",
    "# count_series will already be sorted in descending order by default.\n",
    "print(count_series)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
